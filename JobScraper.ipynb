{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa6c934",
   "metadata": {},
   "source": [
    "# Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdbe15db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a499511",
   "metadata": {},
   "source": [
    "# Indeed.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc3c3bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_Indeed(page):\n",
    "    headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'}\n",
    "    url=f\"https://in.indeed.com/jobs?q=data%20scientist&l=India&start={page}\"\n",
    "    r=requests.get(url,headers)\n",
    "    soup=BeautifulSoup(r.content,'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a69a7e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_Indeed(soup):\n",
    "    divs=soup.find_all('div',class_='job_seen_beacon')\n",
    "    for item in divs:\n",
    "        title=item.find('h2').text.strip()\n",
    "        title=title.split('new')\n",
    "        if len(title)>1:\n",
    "          title=title[1]\n",
    "        else:\n",
    "          title=title[0]\n",
    "        company=item.find('span',class_='companyName').text.strip()\n",
    "        location=item.find('div',class_='companyLocation').text.strip()\n",
    "        date=item.find('span',class_='date').text.strip()\n",
    "        Indeed_jobs={'title':title,'company':company,'location':location,'dateposted':date}\n",
    "        job.append(Indeed_jobs)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20064849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "861d1389",
   "metadata": {},
   "source": [
    "# Linked In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18b2794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_LinkedIn(page):\n",
    "    headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'}\n",
    "    url=f'https://www.linkedin.com/jobs/search/?geoId=102713980&keywords=data%20scientist&start={page}'\n",
    "    r=requests.get(url,headers)\n",
    "    soup1=BeautifulSoup(r.content,'html.parser')\n",
    "    return soup1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1e96914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_LinkedIn(soup1):\n",
    "    divs=soup1.find_all('div',class_='base-card base-card--link base-search-card base-search-card--link job-search-card')\n",
    "    for item in divs:\n",
    "        title=item.find('a').text.strip()\n",
    "        company=item.find('a',class_=\"hidden-nested-link\").text.strip()\n",
    "        location=item.find('span',class_=\"job-search-card__location\").text.strip()\n",
    "        date=item.find('time').text.strip()\n",
    "        linkedinjobs={'title':title,'company':company,'location':location,'dateposted':date}\n",
    "        job1.append(linkedinjobs)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0988e6",
   "metadata": {},
   "source": [
    "# Shine.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "707b20e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_Shine(page):\n",
    "    headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'}\n",
    "    url=f'https://www.shine.com/job-search/data-scientist-jobs-={page}?q=Data%20Scientist'\n",
    "    r=requests.get(url,headers)\n",
    "    soup2=BeautifulSoup(r.content,'html.parser')\n",
    "    return soup2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "845b4227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_Shine(soup2):\n",
    "    divs=soup2.find_all('div',class_='ParentClass')\n",
    "    for item in divs:\n",
    "        job=item.find_all('h2')\n",
    "        for i in job:\n",
    "            title.append(str(i).split('>')[1].split('<')[0])\n",
    "        comp=item.find_all('div',class_=\"jobCard_jobCard_cName__mYnow\")\n",
    "        for j in comp:\n",
    "            company.append(str(j).split('<span>')[1].split('<')[0])\n",
    "        loc=item.find_all('div',class_=\"jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\")\n",
    "        for k in loc:\n",
    "            location.append(str(k).split('>')[1].split('<')[0])\n",
    "        posted=item.find_all('div',class_=\"jobCard_jobCard_features__wJid6\")\n",
    "        for l in posted:\n",
    "            dateposted.append(str(l).split('<span>')[1].split('<')[0])    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851a8bf7",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5394aae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "job=[]\n",
    "job1=[]\n",
    "title=[]\n",
    "company=[]\n",
    "location=[]\n",
    "dateposted=[]\n",
    "\n",
    "\n",
    "#indeed\n",
    "for i in range(0,200,10):\n",
    "    c=extract_Indeed(i)\n",
    "    transform_Indeed(c)   \n",
    "Indeed=pd.DataFrame(job)\n",
    "\n",
    "\n",
    "#linkedin\n",
    "for i in range(0,200,25):\n",
    "    c1=extract_LinkedIn(i)\n",
    "    transform_LinkedIn(c1)\n",
    "LinkedIn=pd.DataFrame(job1)\n",
    "\n",
    "#shine.com\n",
    "for i in range(1,30,1):\n",
    "    c=extract_Shine(0)\n",
    "    transform_Shine(c)\n",
    "    data=list(zip(title,company,location,dateposted))\n",
    "df_shine=pd.DataFrame(data,columns=['title','company','location','dateposted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cbb67ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined entries size= 1064\n",
      "Duplicate entries found = 721\n",
      "Total unique entries = 343\n"
     ]
    }
   ],
   "source": [
    "final_df=pd.concat([Indeed,LinkedIn,df_shine])\n",
    "print('Combined entries size=',len(final_df))\n",
    "final_df=final_df.reset_index(drop=True)\n",
    "#checking for duplicate entries and deleting them\n",
    "print('Duplicate entries found =' ,len(final_df[final_df.duplicated()]))\n",
    "final_df=final_df.drop_duplicates()\n",
    "final_df=final_df.reset_index(drop=True)\n",
    "end=time.time()\n",
    "print('Total unique entries =',len(final_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c0e0d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time of execution = 59.1785 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Total time of execution =\",round(end-start,5),'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaf00841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>dateposted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>HP</td>\n",
       "      <td>Bengaluru, Karnataka</td>\n",
       "      <td>Posted1 day ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>JPMorgan Chase Bank, N.A.</td>\n",
       "      <td>Bengaluru, Karnataka</td>\n",
       "      <td>PostedJust posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Codvo.ai</td>\n",
       "      <td>Remote</td>\n",
       "      <td>PostedToday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>MedTourEasy</td>\n",
       "      <td>Remote</td>\n",
       "      <td>PostedToday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist â€“ AI / Deep Learning for Automa...</td>\n",
       "      <td>Bosch Group</td>\n",
       "      <td>Bengaluru, Karnataka</td>\n",
       "      <td>PostedJust posted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                     Data Scientist   \n",
       "1                                     Data Scientist   \n",
       "2                                     Data Scientist   \n",
       "3                                     Data Scientist   \n",
       "4  Data Scientist â€“ AI / Deep Learning for Automa...   \n",
       "\n",
       "                     company              location         dateposted  \n",
       "0                         HP  Bengaluru, Karnataka    Posted1 day ago  \n",
       "1  JPMorgan Chase Bank, N.A.  Bengaluru, Karnataka  PostedJust posted  \n",
       "2                   Codvo.ai                Remote        PostedToday  \n",
       "3                MedTourEasy                Remote        PostedToday  \n",
       "4                Bosch Group  Bengaluru, Karnataka  PostedJust posted  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f54a3883",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(r'C:\\Users\\erict\\Desktop\\Aivamastu\\Jobs_extracted.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b738dab",
   "metadata": {},
   "source": [
    "# Shortcomings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce35dac8",
   "metadata": {},
   "source": [
    "* All data are from the job listings for data scientist(result page), could'nt figure out how to extract data from each job listing individually."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
